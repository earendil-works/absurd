#!/usr/bin/env python3
import json
import os
import subprocess
import sys
import shutil
import textwrap
from urllib.request import urlopen
from urllib.error import URLError
from optparse import OptionParser, IndentedHelpFormatter


SQL_URL = "https://raw.githubusercontent.com/earendil-works/absurd/refs/heads/main/sql/absurd.sql"


def get_term_width():
    """Get terminal width for formatting."""
    try:
        return shutil.get_terminal_size().columns
    except Exception:
        return 80


class CleanHelpFormatter(IndentedHelpFormatter):
    """Custom formatter with better spacing and formatting."""

    def __init__(self):
        IndentedHelpFormatter.__init__(
            self,
            indent_increment=2,
            max_help_position=30,
            width=get_term_width(),
            short_first=1,
        )

    def format_option(self, option):
        result = []
        opts = self.option_strings[option]
        opt_width = self.help_position - self.current_indent - 2

        if len(opts) > opt_width:
            opts = "%*s%s\n" % (self.current_indent, "", opts)
            indent_first = self.help_position
        else:
            opts = "%*s%-*s  " % (self.current_indent, "", opt_width, opts)
            indent_first = 0

        result.append(opts)

        if option.help:
            help_text = self.expand_default(option)
            help_lines = []

            help_lines = textwrap.wrap(help_text, self.width - self.help_position)

            result.append("%*s%s\n" % (indent_first, "", help_lines[0]))
            for line in help_lines[1:]:
                result.append("%*s%s\n" % (self.help_position, "", line))
        elif opts[-1] != "\n":
            result.append("\n")

        return "".join(result)


def build_database_config(host=None, port=None, user=None, database=None):
    """Build a dict with database configuration."""
    return {
        "host": host or os.getenv("PGHOST", "localhost"),
        "port": port or os.getenv("PGPORT", "5432"),
        "user": user or os.getenv("PGUSER", os.getenv("USER", "")),
        "database": database or os.getenv("PGDATABASE", os.getenv("USER", "")),
    }


def config_from_options(options):
    """Shortcut to construct a database config from parsed options."""
    return build_database_config(
        options.host,
        options.port,
        options.user,
        options.database,
    )


def build_psql_command(config, extra_args=None):
    """Construct the base psql command with optional additional arguments."""
    cmd = [
        "psql",
        "-X",
        "-h",
        config["host"],
        "-p",
        config["port"],
        "-U",
        config["user"],
        "-d",
        config["database"],
    ]

    if extra_args:
        cmd.extend(extra_args)

    return cmd


def get_common_db_details(config):
    """Return standard database connection details for verbose output."""
    return [
        ("Host", config["host"]),
        ("Port", config["port"]),
        ("User", config["user"]),
        ("Database", config["database"]),
    ]


def print_verbose_configuration(enabled, details):
    """Print a formatted configuration block when verbose output is enabled."""
    if not enabled:
        return
    print("Configuration:")
    for label, value in details:
        print(f"  {label}: {value}")


def run_psql(
    config,
    query=None,
    *,
    tuples_only=False,
    no_align=False,
    extra_args=None,
    input_data=None,
    error_message=None,
):
    """
    Execute a PostgreSQL command. Returns stripped stdout for queries and the
    CompletedProcess for other invocations.
    """
    cmd_args = []

    if tuples_only:
        cmd_args.append("-t")
    if no_align:
        cmd_args.append("-A")
    if extra_args:
        cmd_args.extend(extra_args)
    if query is not None:
        cmd_args.extend(["-c", query])

    message = error_message
    if message is None:
        message = (
            "Error executing query"
            if query is not None
            else "Error executing psql command"
        )

    env = os.environ.copy()
    env["PGPASSWORD"] = os.getenv("PGPASSWORD", "")
    try:
        result = subprocess.run(
            build_psql_command(config, cmd_args),
            input=input_data,
            capture_output=True,
            text=True,
            check=True,
            env=env,
        )
    except subprocess.CalledProcessError as e:
        print(f"{message}: {e.stderr}", file=sys.stderr)
        sys.exit(1)

    if query is not None:
        return result.stdout.strip()
    return result


def queue_exists(config, queue_name):
    """Check if a queue exists."""
    result = run_psql(
        config,
        f"SELECT COUNT(*) FROM absurd.queues WHERE queue_name = '{queue_name}';",
        tuples_only=True,
        no_align=True,
    )
    return int(result) > 0


def build_json_params(param_list, base_params=None):
    """
    Build JSON parameters from -p flags and optional base --params.

    Supports:
      -p foo=bar           -> {"foo": "bar"}
      -p count:=42         -> {"count": 42}
      -p enabled:=true     -> {"enabled": true}
      -p tags:='["a","b"]' -> {"tags": ["a","b"]}
      -p user.name=Alice   -> {"user": {"name": "Alice"}}
      --params '{"x":1}'   -> merged with -p flags
    """
    result = {}

    if base_params:
        try:
            result = json.loads(base_params)
            if not isinstance(result, dict):
                raise ValueError("--params must be a JSON object")
        except json.JSONDecodeError as e:
            print(f"Error parsing --params: {e}", file=sys.stderr)
            sys.exit(1)

    for param in param_list:
        if ":=" in param:
            key, value_str = param.split(":=", 1)
            try:
                value = json.loads(value_str)
            except json.JSONDecodeError as e:
                print(f"Error parsing JSON value in '{param}': {e}", file=sys.stderr)
                sys.exit(1)
        elif "=" in param:
            key, value = param.split("=", 1)
        else:
            print(
                f"Invalid parameter format: '{param}' (expected key=value or key:=json)",
                file=sys.stderr,
            )
            sys.exit(1)

        set_nested_value(result, key, value)

    return json.dumps(result)


def set_nested_value(obj, path, value):
    """Set a value in a nested dictionary using dot notation."""
    keys = path.split(".")
    current = obj

    for key in keys[:-1]:
        if key not in current:
            current[key] = {}
        elif not isinstance(current[key], dict):
            print(
                f"Error: Cannot set nested value, '{key}' is not an object",
                file=sys.stderr,
            )
            sys.exit(1)
        current = current[key]

    current[keys[-1]] = value


def add_db_options(parser):
    """Add common database connection options to a parser."""
    parser.add_option("-h", "--host", dest="host", metavar="HOST", help="Database host")
    parser.add_option("-p", "--port", dest="port", metavar="PORT", help="Database port")
    parser.add_option("-U", "--user", dest="user", metavar="USER", help="Database user")
    parser.add_option(
        "-d", "--database", dest="database", metavar="DB", help="Database name"
    )
    parser.add_option(
        "-v",
        "--verbose",
        dest="verbose",
        action="store_true",
        default=False,
        help="Verbose output",
    )


def build_command_parser(usage):
    """Create an OptionParser with common Absurd defaults."""
    parser = OptionParser(
        usage=usage,
        add_help_option=False,
        formatter=CleanHelpFormatter(),
    )
    add_db_options(parser)
    parser.add_option("--help", action="store_true", help="Show this help message")
    return parser


def parse_args_with_help(parser, args, examples=None):
    """Parse args and handle --help in a consistent way."""
    options, remaining = parser.parse_args(args)
    if getattr(options, "help", False):
        parser.print_help()
        if examples:
            print("\nExamples:")
            for example in examples:
                print(f"  {example}")
        sys.exit(0)
    return options, remaining


def ensure_queue_exists(config, queue_name):
    """Exit with error if queue is missing."""
    if not queue_exists(config, queue_name):
        print(f"Queue '{queue_name}' does not exist", file=sys.stderr)
        sys.exit(1)


def cmd_cleanup(args):
    """Clean up old completed, failed, or cancelled tasks and events."""
    usage = "usage: %prog cleanup [options] QUEUE_NAME TTL_DAYS"
    parser = build_command_parser(usage)
    parser.add_option(
        "-l",
        "--limit",
        dest="limit",
        type="int",
        default=1000,
        help="Batch size for deletions (default: 1000)",
    )
    parser.add_option(
        "-n",
        "--dry-run",
        dest="dry_run",
        action="store_true",
        default=False,
        help="Show what would be deleted without actually deleting",
    )
    examples = [
        "absurdctl cleanup myqueue 30",
        "absurdctl cleanup --dry-run -v myqueue 30",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if len(args) != 2:
        print(
            "Error: Missing required arguments QUEUE_NAME and TTL_DAYS", file=sys.stderr
        )
        parser.print_help()
        sys.exit(1)

    queue_name = args[0]
    try:
        ttl_days = int(args[1])
    except ValueError:
        print(
            f"Error: TTL_DAYS must be a positive integer, got: {args[1]}",
            file=sys.stderr,
        )
        sys.exit(1)

    config = config_from_options(options)
    ensure_queue_exists(config, queue_name)

    ttl_seconds = ttl_days * 24 * 60 * 60

    print_verbose_configuration(
        options.verbose,
        [
            ("Queue", queue_name),
            ("TTL", f"{ttl_days} days ({ttl_seconds} seconds)"),
        ]
        + get_common_db_details(config)
        + [
            ("Limit", options.limit),
            ("Dry run", options.dry_run),
        ],
    )

    if options.dry_run:
        print("DRY RUN MODE - No data will be deleted")

        task_count = run_psql(
            config,
            f"""SELECT COUNT(*) FROM absurd.t_{queue_name} t
                LEFT JOIN absurd.r_{queue_name} r ON r.run_id = t.last_attempt_run
                WHERE t.state IN ('completed', 'failed', 'cancelled')
                AND ((t.state = 'completed' AND r.completed_at < NOW() - INTERVAL '{ttl_seconds} seconds')
                OR (t.state = 'failed' AND r.failed_at < NOW() - INTERVAL '{ttl_seconds} seconds')
                OR (t.state = 'cancelled' AND t.cancelled_at < NOW() - INTERVAL '{ttl_seconds} seconds'));""",
            tuples_only=True,
            no_align=True,
        )

        event_count = run_psql(
            config,
            f"SELECT COUNT(*) FROM absurd.e_{queue_name} WHERE emitted_at < NOW() - INTERVAL '{ttl_seconds} seconds';",
            tuples_only=True,
            no_align=True,
        )

        print(f"Would delete {task_count} tasks and {event_count} events")
        return

    print(f"Starting cleanup for queue '{queue_name}' (TTL: {ttl_days} days)")

    total_tasks_deleted = 0
    total_events_deleted = 0
    iteration = 0

    while True:
        iteration += 1

        if options.verbose:
            print(f"Iteration {iteration}...")

        tasks_deleted = int(
            run_psql(
                config,
                f"SELECT absurd.cleanup_tasks('{queue_name}', {ttl_seconds}, {options.limit});",
                tuples_only=True,
                no_align=True,
            )
        )
        total_tasks_deleted += tasks_deleted

        if options.verbose and tasks_deleted > 0:
            print(f"  Deleted {tasks_deleted} tasks")

        events_deleted = int(
            run_psql(
                config,
                f"SELECT absurd.cleanup_events('{queue_name}', {ttl_seconds}, {options.limit});",
                tuples_only=True,
                no_align=True,
            )
        )
        total_events_deleted += events_deleted

        if options.verbose and events_deleted > 0:
            print(f"  Deleted {events_deleted} events")

        if tasks_deleted == 0 and events_deleted == 0:
            break

        if tasks_deleted > 0 or events_deleted > 0:
            print(f"Deleted {tasks_deleted} tasks, {events_deleted} events")

    print(
        f"Cleanup complete: {total_tasks_deleted} tasks, {total_events_deleted} events deleted in {iteration} iterations"
    )


def cmd_create_queue(args):
    """Create a new Absurd queue."""
    usage = "usage: %prog create-queue [options] QUEUE_NAME"
    parser = build_command_parser(usage)

    options, args = parse_args_with_help(
        parser, args, ["absurdctl create-queue myqueue"]
    )

    if len(args) != 1:
        print("Error: Missing required argument QUEUE_NAME", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    queue_name = args[0]
    config = config_from_options(options)

    print_verbose_configuration(
        options.verbose,
        [("Queue", queue_name)] + get_common_db_details(config),
    )
    if options.verbose:
        print(f"Creating queue '{queue_name}'...")

    run_psql(config, f"SELECT absurd.create_queue('{queue_name}');")
    print(f"Queue '{queue_name}' created successfully")


def cmd_drop_queue(args):
    """Drop an existing Absurd queue."""
    usage = "usage: %prog drop-queue [options] QUEUE_NAME"
    parser = build_command_parser(usage)
    parser.add_option(
        "-y",
        "--yes",
        dest="yes",
        action="store_true",
        default=False,
        help="Skip confirmation prompt",
    )
    examples = [
        "absurdctl drop-queue myqueue",
        "absurdctl drop-queue --yes myqueue",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if len(args) != 1:
        print("Error: Missing required argument QUEUE_NAME", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    queue_name = args[0]
    config = config_from_options(options)

    ensure_queue_exists(config, queue_name)

    print_verbose_configuration(
        options.verbose,
        [("Queue", queue_name)] + get_common_db_details(config),
    )

    if not options.yes:
        print(
            f"WARNING: This will permanently delete queue '{queue_name}' and all its data."
        )
        response = input("Are you sure you want to continue? (yes/no): ")
        if response != "yes":
            print("Operation cancelled")
            return

    if options.verbose:
        print(f"Dropping queue '{queue_name}'...")

    run_psql(config, f"SELECT absurd.drop_queue('{queue_name}');")
    print(f"Queue '{queue_name}' dropped successfully")


def cmd_list_queues(args):
    """List all existing Absurd queues."""
    usage = "usage: %prog list-queues [options]"
    parser = build_command_parser(usage)

    options, args = parse_args_with_help(parser, args)

    config = config_from_options(options)

    result = run_psql(
        config, "SELECT * FROM absurd.list_queues();", tuples_only=True, no_align=True
    ).strip()
    if result:
        print(result)


def cmd_init(args):
    """Initialize the Absurd schema by applying absurd.sql."""
    usage = "usage: %prog init [options]"
    parser = build_command_parser(usage)

    options, args = parse_args_with_help(parser, args, ["absurdctl init"])

    config = config_from_options(options)

    print_verbose_configuration(options.verbose, get_common_db_details(config))

    script_dir = os.path.dirname(os.path.abspath(__file__))
    local_sql_path = os.path.join(script_dir, "sql", "absurd.sql")

    if os.path.exists(local_sql_path):
        if options.verbose:
            print(f"Using local SQL file: {local_sql_path}")

        result = run_psql(
            config,
            extra_args=["-f", local_sql_path],
            error_message="Error applying SQL file",
        )
    else:
        if options.verbose:
            print(f"Local SQL file not found, fetching from: {SQL_URL}")
        try:
            with urlopen(SQL_URL) as response:
                sql_content = response.read().decode("utf-8")
        except URLError as e:
            print(f"Error downloading SQL file from GitHub: {e}", file=sys.stderr)
            sys.exit(1)
        result = run_psql(
            config, input_data=sql_content, error_message="Error applying SQL file"
        )

    if options.verbose and result.stdout:
        print(result.stdout)
    print("Absurd schema initialized successfully")


def cmd_spawn_task(args):
    """Spawn a new task."""
    usage = "usage: %prog spawn-task [options] TASK_NAME"
    parser = build_command_parser(usage)

    parser.add_option(
        "-q",
        "--queue",
        dest="queue",
        metavar="NAME",
        help="Queue name (default: default)",
    )

    parser.add_option(
        "-P",
        "--param",
        dest="params",
        action="append",
        default=[],
        metavar="K=V",
        help="Task parameter. Use -P key=value for strings or -P key:=json for JSON values. "
        "Supports dotted paths for nested objects (e.g., -P user.name=Alice)",
    )
    parser.add_option(
        "--params",
        dest="base_params",
        metavar="JSON",
        help="Base JSON object for parameters (will be merged with -P flags)",
    )
    parser.add_option(
        "-H",
        "--header",
        dest="headers",
        action="append",
        default=[],
        metavar="K=V",
        help="Task header as key=value pair",
    )

    parser.add_option(
        "--max-attempts",
        dest="max_attempts",
        type="int",
        metavar="N",
        help="Maximum number of retry attempts",
    )
    parser.add_option(
        "--retry-kind",
        dest="retry_kind",
        metavar="KIND",
        help="Retry strategy: fixed, exponential, or none",
    )
    parser.add_option(
        "--retry-base",
        dest="retry_base",
        type="int",
        metavar="SECS",
        help="Base retry delay in seconds",
    )
    parser.add_option(
        "--retry-factor",
        dest="retry_factor",
        type="float",
        metavar="FACTOR",
        help="Exponential backoff multiplier (for exponential retry)",
    )
    parser.add_option(
        "--retry-max",
        dest="retry_max",
        type="int",
        metavar="SECS",
        help="Maximum retry delay cap in seconds",
    )

    parser.add_option(
        "--max-duration",
        dest="max_duration",
        type="int",
        metavar="SECS",
        help="Maximum task execution duration in seconds",
    )
    parser.add_option(
        "--max-delay",
        dest="max_delay",
        type="int",
        metavar="SECS",
        help="Maximum delay before task must start in seconds",
    )

    examples = [
        "absurdctl spawn-task my-task -P foo=bar -P count:=42",
        "absurdctl spawn-task my-task -P user.name=Alice -P user.age:=30",
        'absurdctl spawn-task my-task --params \'{"foo":"bar"}\' -P extra=value',
        "absurdctl spawn-task my-task -P email=test@example.com -q myqueue --max-attempts 5",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if len(args) != 1:
        print("Error: Missing required argument TASK_NAME", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    task_name = args[0]
    config = config_from_options(options)

    params_json = build_json_params(options.params, options.base_params)

    headers_json = "NULL"
    if options.headers:
        headers_dict = {}
        for header in options.headers:
            if "=" not in header:
                print(
                    f"Invalid header format: '{header}' (expected key=value)",
                    file=sys.stderr,
                )
                sys.exit(1)
            key, value = header.split("=", 1)
            headers_dict[key] = value
        headers_json = f"'{json.dumps(headers_dict)}'::jsonb"

    retry_json = "NULL"
    if (
        options.retry_kind
        or options.retry_base
        or options.retry_factor
        or options.retry_max
    ):
        retry = {"kind": options.retry_kind or "exponential"}
        if options.retry_base:
            retry["baseSeconds"] = options.retry_base
        if options.retry_factor:
            retry["factor"] = options.retry_factor
        if options.retry_max:
            retry["maxSeconds"] = options.retry_max
        retry_json = f"'{json.dumps(retry)}'::jsonb"

    cancellation_json = "NULL"
    if options.max_duration or options.max_delay:
        cancellation = {}
        if options.max_duration:
            cancellation["maxDuration"] = options.max_duration
        if options.max_delay:
            cancellation["maxDelay"] = options.max_delay
        cancellation_json = f"'{json.dumps(cancellation)}'::jsonb"

    queue = options.queue or "default"

    ensure_queue_exists(config, queue)

    details = [
        ("Task", task_name),
        ("Queue", queue),
        ("Params", params_json),
    ]
    if headers_json != "NULL":
        details.append(("Headers", headers_json))
    if options.max_attempts:
        details.append(("Max attempts", options.max_attempts))
    if retry_json != "NULL":
        details.append(("Retry strategy", retry_json))
    if cancellation_json != "NULL":
        details.append(("Cancellation", cancellation_json))
    details.extend(get_common_db_details(config))
    print_verbose_configuration(options.verbose, details)

    query = f"""
        SELECT task_id, run_id, attempt
        FROM absurd.spawn_task(
            '{queue}',
            '{task_name}',
            '{params_json}'::jsonb,
            {headers_json},
            {options.max_attempts or "NULL"},
            {retry_json},
            {cancellation_json}
        );
    """

    result = run_psql(config, query, tuples_only=True, no_align=True)

    if result:
        task_id, run_id, attempt = result.split("|")
        print(f"Task spawned successfully:")
        print(f"  Task ID: {task_id}")
        print(f"  Run ID: {run_id}")
        print(f"  Attempt: {attempt}")
    else:
        print("Task spawned, but no result returned", file=sys.stderr)


def format_error_like(data):
    """Try to extract and format error-like objects with name, message, and stack."""
    if not isinstance(data, dict):
        return None

    if "name" in data and "message" in data and "stack" in data:
        return {
            "name": data["name"],
            "message": data["message"],
            "stack": data["stack"],
        }
    return None


def format_json_value(value, indent=0):
    """Format a JSON value with proper indentation."""
    if value is None:
        return "null"

    # Check if it's an error-like object
    error_info = format_error_like(value)
    if error_info:
        lines = []
        lines.append(f"{error_info['name']}")
        lines.append(f"\nMessage:")
        lines.append(f"  {error_info['message']}")
        if error_info["stack"]:
            lines.append(f"\nStack trace:")
            for line in error_info["stack"].split("\n"):
                lines.append(f"  {line}")
        return "\n".join(lines)

    # Otherwise, render as JSON
    return json.dumps(value, indent=2)


def format_timestamp(ts_str):
    """Format a timestamp string in a human-readable way."""
    if not ts_str:
        return "—"
    try:
        from datetime import datetime

        dt = datetime.fromisoformat(ts_str.replace("Z", "+00:00"))
        return dt.strftime("%b %d, %Y %I:%M:%S %p")
    except:
        return ts_str


def format_age(timestamp_str):
    """Format a timestamp as a relative age (e.g., '2h ago', '3d ago')."""
    if not timestamp_str:
        return "—"
    try:
        from datetime import datetime, timezone

        dt = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        now = datetime.now(timezone.utc)
        delta = now - dt

        seconds = delta.total_seconds()
        if seconds < 60:
            return f"{int(seconds)}s ago"
        elif seconds < 3600:
            return f"{int(seconds / 60)}m ago"
        elif seconds < 86400:
            return f"{int(seconds / 3600)}h ago"
        elif seconds < 604800:
            return f"{int(seconds / 86400)}d ago"
        else:
            return f"{int(seconds / 604800)}w ago"
    except:
        return timestamp_str


def cmd_list_tasks(args):
    """List tasks across queues with filtering options."""
    usage = "usage: %prog list-tasks [options]"
    parser = build_command_parser(usage)
    parser.add_option(
        "-q",
        "--queue",
        dest="queue",
        metavar="NAME",
        help="Filter by queue name",
    )
    parser.add_option(
        "-n",
        "--task-name",
        dest="task_name",
        metavar="NAME",
        help="Filter by task name (exact match)",
    )
    parser.add_option(
        "-s",
        "--status",
        dest="status",
        metavar="STATUS",
        help="Filter by status (pending, running, sleeping, completed, failed, cancelled)",
    )
    parser.add_option(
        "-l",
        "--limit",
        dest="limit",
        type="int",
        default=50,
        metavar="N",
        help="Maximum number of tasks to display (default: 50)",
    )

    examples = [
        "absurdctl list-tasks",
        "absurdctl list-tasks --queue=default",
        "absurdctl list-tasks --status=failed",
        "absurdctl list-tasks --task-name=my-task --queue=default",
        "absurdctl list-tasks --limit=100",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    config = config_from_options(options)

    # Validate status if provided
    valid_statuses = [
        "pending",
        "running",
        "sleeping",
        "completed",
        "failed",
        "cancelled",
    ]
    if options.status and options.status not in valid_statuses:
        print(
            f"Error: Invalid status '{options.status}'. Must be one of: {', '.join(valid_statuses)}",
            file=sys.stderr,
        )
        sys.exit(1)

    # Get list of queues
    queues_result = run_psql(
        config,
        "SELECT queue_name FROM absurd.queues;",
        tuples_only=True,
        no_align=True,
    )

    if not queues_result:
        print("No queues found in the database", file=sys.stderr)
        sys.exit(0)

    queues = [q for q in queues_result.strip().split("\n") if q]

    # Filter to specific queue if requested
    if options.queue:
        if options.queue not in queues:
            print(f"Queue '{options.queue}' does not exist", file=sys.stderr)
            sys.exit(1)
        queues = [options.queue]

    # Build query for each queue and collect results
    all_tasks = []

    for queue in queues:
        # Build WHERE clause based on filters
        where_clauses = []
        if options.task_name:
            where_clauses.append(f"t.task_name = '{options.task_name}'")
        if options.status:
            where_clauses.append(f"t.state = '{options.status}'")

        where_clause = ""
        if where_clauses:
            where_clause = "WHERE " + " AND ".join(where_clauses)

        query = f"""
            SELECT
                t.task_id,
                r.run_id,
                t.task_name,
                '{queue}' as queue_name,
                t.state,
                r.attempt,
                t.max_attempts,
                COALESCE(r.completed_at, r.failed_at, r.started_at, r.created_at) AS updated_at
            FROM absurd.t_{queue} t
            LEFT JOIN absurd.r_{queue} r ON r.run_id = t.last_attempt_run
            {where_clause}
            ORDER BY updated_at DESC
            LIMIT {options.limit}
        """

        result = run_psql(
            config,
            query,
            tuples_only=True,
            no_align=True,
        )

        if result:
            for line in result.strip().split("\n"):
                parts = line.split("|")
                if len(parts) >= 8:
                    all_tasks.append(
                        {
                            "task_id": parts[0],
                            "run_id": parts[1] if parts[1] else "—",
                            "task_name": parts[2],
                            "queue": parts[3],
                            "status": parts[4],
                            "attempt": parts[5],
                            "max_attempts": parts[6] if parts[6] else "∞",
                            "updated_at": parts[7],
                        }
                    )

    # Sort all tasks by updated_at descending
    all_tasks.sort(key=lambda x: x["updated_at"], reverse=True)

    # Apply global limit
    all_tasks = all_tasks[: options.limit]

    if not all_tasks:
        print("No tasks found")
        return

    # Print tasks with full identifiers on two lines for easier copying.
    for task in all_tasks:
        attempts = f"{task['attempt']}/{task['max_attempts']}"
        age = format_age(task["updated_at"])
        print(f"task_id={task['task_id']}")
        print(f"  run_id={task['run_id']}")
        print(f"  attempts={attempts}")
        print(f"  age={age}")
        print(f"  queue={task['queue']}")
        print(f"  task_name={task['task_name']}")
        print(f"  status={task['status']}")
        print()

    print()
    print(f"Total: {len(all_tasks)} task(s)")


def cmd_dump_task(args):
    """Dump task or run details including checkpoints."""
    usage = "usage: %prog dump-task [options]"
    parser = build_command_parser(usage)
    parser.add_option(
        "--task-id",
        dest="task_id",
        metavar="UUID",
        help="Task ID to dump",
    )
    parser.add_option(
        "--run-id",
        dest="run_id",
        metavar="UUID",
        help="Run ID to dump",
    )

    examples = [
        "absurdctl dump-task --task-id=019a32d3-8425-7ae2-a5af-2f17a6707666",
        "absurdctl dump-task --run-id=019a32d3-8425-7ae2-a5af-2f17a6707666",
    ]

    options, args = parse_args_with_help(parser, args, examples)

    if not options.task_id and not options.run_id:
        print("Error: Either --task-id or --run-id must be specified", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    if options.task_id and options.run_id:
        print("Error: Cannot specify both --task-id and --run-id", file=sys.stderr)
        parser.print_help()
        sys.exit(1)

    config = config_from_options(options)

    # Get list of queues
    queues_result = run_psql(
        config,
        "SELECT queue_name FROM absurd.queues;",
        tuples_only=True,
        no_align=True,
    )

    if not queues_result:
        print("No queues found in the database", file=sys.stderr)
        sys.exit(1)

    queues = [q for q in queues_result.strip().split("\n") if q]

    # Find which queue contains the task/run
    target_queue = None
    task_id = None

    if options.run_id:
        # Search for run_id across all queues
        for queue in queues:
            result = run_psql(
                config,
                f"SELECT task_id FROM absurd.r_{queue} WHERE run_id = '{options.run_id}';",
                tuples_only=True,
                no_align=True,
            )
            if result:
                target_queue = queue
                task_id = result.strip()
                break

        if not target_queue:
            print(f"Run ID '{options.run_id}' not found in any queue", file=sys.stderr)
            sys.exit(1)
    else:
        # Search for task_id across all queues
        task_id = options.task_id
        for queue in queues:
            result = run_psql(
                config,
                f"SELECT COUNT(*) FROM absurd.t_{queue} WHERE task_id = '{task_id}';",
                tuples_only=True,
                no_align=True,
            )
            if result and int(result.strip()) > 0:
                target_queue = queue
                break

        if not target_queue:
            print(f"Task ID '{task_id}' not found in any queue", file=sys.stderr)
            sys.exit(1)

    # Fetch task and runs
    if options.run_id:
        # Fetch specific run
        runs_query = f"""
            SELECT
                t.task_id,
                r.run_id,
                t.task_name,
                t.state,
                r.state as run_state,
                r.attempt,
                t.max_attempts,
                t.params,
                t.retry_strategy,
                t.headers,
                COALESCE(r.failure_reason, r.result) AS final_state,
                r.created_at,
                r.started_at,
                r.completed_at,
                r.failed_at,
                t.cancelled_at,
                COALESCE(r.completed_at, r.failed_at, r.started_at, r.created_at) AS updated_at
            FROM absurd.t_{target_queue} t
            JOIN absurd.r_{target_queue} r ON r.task_id = t.task_id
            WHERE r.run_id = '{options.run_id}'
        """
    else:
        # Fetch all runs for task
        runs_query = f"""
            SELECT
                t.task_id,
                r.run_id,
                t.task_name,
                t.state,
                r.state as run_state,
                r.attempt,
                t.max_attempts,
                t.params,
                t.retry_strategy,
                t.headers,
                COALESCE(r.failure_reason, r.result) AS final_state,
                r.created_at,
                r.started_at,
                r.completed_at,
                r.failed_at,
                t.cancelled_at,
                COALESCE(r.completed_at, r.failed_at, r.started_at, r.created_at) AS updated_at
            FROM absurd.t_{target_queue} t
            JOIN absurd.r_{target_queue} r ON r.task_id = t.task_id
            WHERE t.task_id = '{task_id}'
            ORDER BY r.attempt
        """

    runs_result = run_psql(
        config,
        runs_query,
        tuples_only=True,
        no_align=True,
    )

    if not runs_result:
        print("No data found", file=sys.stderr)
        sys.exit(1)

    # Parse runs
    runs = []
    for line in runs_result.strip().split("\n"):
        parts = line.split("|")
        if len(parts) >= 17:
            run = {
                "task_id": parts[0],
                "run_id": parts[1],
                "task_name": parts[2],
                "task_state": parts[3],
                "run_state": parts[4],
                "attempt": parts[5],
                "max_attempts": parts[6] if parts[6] else None,
                "params": json.loads(parts[7]) if parts[7] else None,
                "retry_strategy": json.loads(parts[8]) if parts[8] else None,
                "headers": json.loads(parts[9]) if parts[9] else None,
                "final_state": json.loads(parts[10]) if parts[10] else None,
                "created_at": parts[11],
                "started_at": parts[12],
                "completed_at": parts[13],
                "failed_at": parts[14],
                "cancelled_at": parts[15],
                "updated_at": parts[16],
            }
            runs.append(run)

    # For each run, fetch checkpoints and waits
    for run in runs:
        # Fetch checkpoints
        checkpoints_query = f"""
            SELECT
                checkpoint_name,
                state,
                status,
                owner_run_id,
                updated_at
            FROM absurd.c_{target_queue}
            WHERE task_id = '{run['task_id']}' AND owner_run_id = '{run['run_id']}'
            ORDER BY updated_at DESC
        """

        checkpoints_result = run_psql(
            config,
            checkpoints_query,
            tuples_only=True,
            no_align=True,
        )

        checkpoints = []
        if checkpoints_result:
            for line in checkpoints_result.strip().split("\n"):
                parts = line.split("|")
                if len(parts) >= 5:
                    checkpoints.append(
                        {
                            "name": parts[0],
                            "state": json.loads(parts[1]) if parts[1] else None,
                            "status": parts[2],
                            "owner_run_id": parts[3],
                            "updated_at": parts[4],
                        }
                    )

        run["checkpoints"] = checkpoints

        # Fetch wait states
        waits_query = f"""
            SELECT
                CASE
                    WHEN r.wake_event IS NOT NULL THEN 'event'
                    WHEN r.available_at IS NOT NULL THEN 'sleep'
                    ELSE NULL
                END AS wait_type,
                r.available_at,
                r.wake_event,
                w.step_name,
                r.event_payload,
                e.payload as event_payload_emitted,
                e.emitted_at,
                COALESCE(w.created_at, r.started_at) as updated_at
            FROM absurd.r_{target_queue} r
            LEFT JOIN absurd.w_{target_queue} w ON w.run_id = r.run_id
            LEFT JOIN absurd.e_{target_queue} e ON e.event_name = r.wake_event
            WHERE r.run_id = '{run['run_id']}' AND r.state = 'sleeping'
        """

        waits_result = run_psql(
            config,
            waits_query,
            tuples_only=True,
            no_align=True,
        )

        waits = []
        if waits_result:
            for line in waits_result.strip().split("\n"):
                parts = line.split("|")
                if len(parts) >= 8 and parts[0]:
                    waits.append(
                        {
                            "wait_type": parts[0],
                            "wake_at": parts[1],
                            "wake_event": parts[2] if parts[2] else None,
                            "step_name": parts[3] if parts[3] else None,
                            "payload": json.loads(parts[4]) if parts[4] else None,
                            "event_payload": json.loads(parts[5]) if parts[5] else None,
                            "emitted_at": parts[6] if parts[6] else None,
                            "updated_at": parts[7],
                        }
                    )

        run["waits"] = waits

    # Now output the results
    print("=" * 80)
    print(f"TASK DUMP")
    print("=" * 80)
    print()

    for idx, run in enumerate(runs):
        if idx > 0:
            print()
            print("-" * 80)
            print()

        print(f"BASIC INFORMATION")
        print(f"  Current status:    {run['run_state']}")
        print(f"  Task Name:         {run['task_name']}")
        print(f"  Queue:             {target_queue}")
        print(f"  Task ID:           {run['task_id']}")
        print(f"  Run ID:            {run['run_id']}")
        print()

        print(f"TIMING")
        print(f"  Created:           {format_timestamp(run['created_at'])}")
        print(f"  Updated:           {format_timestamp(run['updated_at'])}")
        if run["started_at"]:
            print(f"  Started:           {format_timestamp(run['started_at'])}")
        if run["completed_at"]:
            print(f"  Completed:         {format_timestamp(run['completed_at'])}")
        if run["failed_at"]:
            print(f"  Failed:            {format_timestamp(run['failed_at'])}")
        if run["cancelled_at"]:
            print(f"  Cancelled:         {format_timestamp(run['cancelled_at'])}")
        print()

        # Wait states
        if run["waits"]:
            print(f"WAIT STATES")
            for wait in run["waits"]:
                wait_type = (
                    wait["wait_type"].capitalize() + " wait"
                    if wait["wait_type"]
                    else "Wait"
                )
                print(f"  {wait_type}")
                if wait["step_name"]:
                    print(f"    Step:            {wait['step_name']}")
                if wait["wake_at"]:
                    print(f"    Wake at:         {format_timestamp(wait['wake_at'])}")
                if wait["wake_event"]:
                    print(f"    Wake event:      {wait['wake_event']}")
                if wait["emitted_at"]:
                    print(
                        f"    Last emit:       {format_timestamp(wait['emitted_at'])}"
                    )
                print(f"    Updated:         {format_timestamp(wait['updated_at'])}")
                if wait["payload"]:
                    print(f"    Wait payload:")
                    for line in format_json_value(wait["payload"]).split("\n"):
                        print(f"      {line}")
                if wait["event_payload"]:
                    print(f"    Event payload:")
                    for line in format_json_value(wait["event_payload"]).split("\n"):
                        print(f"      {line}")
            print()

        print(f"RETRY INFORMATION")
        max_attempts_str = run["max_attempts"] if run["max_attempts"] else "unlimited"
        print(f"  Attempt:           {run['attempt']} of {max_attempts_str}")
        if run["retry_strategy"]:
            print(f"  Retry Strategy:")
            for line in format_json_value(run["retry_strategy"]).split("\n"):
                print(f"    {line}")
        print()

        # Parameters
        if run["params"]:
            print(f"PARAMETERS")
            for line in format_json_value(run["params"]).split("\n"):
                print(f"  {line}")
            print()

        # Headers
        if run["headers"]:
            print(f"HEADERS")
            for line in format_json_value(run["headers"]).split("\n"):
                print(f"  {line}")
            print()

        # Final state
        if run["final_state"]:
            state_label = "FAILURE" if run["run_state"] == "failed" else "FINAL STATE"
            print(state_label)
            for line in format_json_value(run["final_state"]).split("\n"):
                print(f"  {line}")
            print()

        # Checkpoints
        if run["checkpoints"]:
            print(f"CHECKPOINTS")
            for checkpoint in run["checkpoints"]:
                print(f"  {checkpoint['name']} ({checkpoint['status']})")
                print(
                    f"    Updated:         {format_timestamp(checkpoint['updated_at'])}"
                )
                if checkpoint["state"]:
                    print(f"    State:")
                    for line in format_json_value(checkpoint["state"]).split("\n"):
                        print(f"      {line}")
                print()


def cmd_agent_help(args):
    """Print quick guidance for automated agents."""
    if args:
        print("Error: agent-help does not accept arguments", file=sys.stderr)
        sys.exit(1)

    message = textwrap.dedent(
        """
        This project uses "Absurd", a durable workflow system built on postgres.  It can be
        debugged with the `absurdctl` command-line tool.

        Connection: set PGHOST, PGPORT, PGUSER, PGDATABASE, and PGPASSWORD just like for psql.

        Core commands to explore:
        - list-queues: discover available queues (`absurdctl list-queues`)
        - list-tasks: inspect recent activity in a queue (`absurdctl list-tasks --queue=default`)
        - dump-task: pull full details for a task or run (`absurdctl dump-task --task-id=<uuid>`)
        - spawn-task: enqueue new work (`absurdctl spawn-task my-task`)

        Use `absurdctl <command> --help` to see every option when you need more detail.

        Task state includes all checkpointed step results as JSON.
        """
    ).strip()

    print(message)


def show_help():
    print(
        """Usage: absurdctl COMMAND [OPTIONS]

A command-line utility for managing Absurd queues.

Commands:
  init            Initialize the Absurd schema by applying absurd.sql
  cleanup         Clean up old completed, failed, or cancelled tasks and events
  create-queue    Create a new queue
  drop-queue      Drop an existing queue
  list-queues     List all existing queues
  spawn-task      Spawn a new task
  list-tasks      List tasks with optional filtering
  dump-task       Dump task or run details including checkpoints
  agent-help      Print quick guidance tailored for coding agents
  help            Show this help message

Run 'absurdctl COMMAND --help' for more information on a command.

Environment Variables:
  PGHOST          Database host
  PGPORT          Database port
  PGUSER          Database user
  PGDATABASE      Database name
  PGPASSWORD      Database password (recommended over command line)

Examples:
  absurdctl init
  absurdctl cleanup myqueue 30
  absurdctl create-queue myqueue
  absurdctl drop-queue myqueue --yes
  absurdctl list-queues
  absurdctl spawn-task my-task -P foo=bar -P count:=42
  absurdctl list-tasks --queue=default --status=failed
  absurdctl dump-task --task-id=019a32d3-8425-7ae2-a5af-2f17a6707666
  absurdctl agent-help >> AGENTS.md
"""
    )


def main():
    if len(sys.argv) < 2 or sys.argv[1] in ("help", "--help", "-h"):
        show_help()
        sys.exit(0)

    command = sys.argv[1]
    args = sys.argv[2:]

    if command == "cleanup":
        cmd_cleanup(args)
    elif command == "create-queue":
        cmd_create_queue(args)
    elif command == "drop-queue":
        cmd_drop_queue(args)
    elif command == "list-queues":
        cmd_list_queues(args)
    elif command == "init":
        cmd_init(args)
    elif command == "spawn-task":
        cmd_spawn_task(args)
    elif command == "list-tasks":
        cmd_list_tasks(args)
    elif command == "dump-task":
        cmd_dump_task(args)
    elif command == "agent-help":
        cmd_agent_help(args)
    else:
        print(f"Unknown command: {command}", file=sys.stderr)
        print("")
        show_help()
        sys.exit(1)


if __name__ == "__main__":
    main()
